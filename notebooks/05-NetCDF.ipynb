{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9df44bc3-9380-4e53-9c02-cead3aaff637",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve and print all Spark configuration settings\n",
    "for item in spark.sparkContext.getConf().getAll():\n",
    "    print(f\"{item[0]} = {item[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2864c307-bfc6-4f42-afa3-e25ebb1e964c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"NetCDF Processing\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memoryOverhead\", \"1g\") \\\n",
    "    .config(\"spark.executor.memoryOverhead\", \"1g\") \\\n",
    "    .config(\"spark.driver.cores\", \"4\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb1d83f8-5b63-4532-90e8-45ec30e7811f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sedona.spark import *\n",
    "\n",
    "config = SedonaContext.builder() .\\\n",
    "    config('spark.jars.packages',\n",
    "           'org.apache.sedona:sedona-spark-shaded-3.3_2.12:1.7.1,'\n",
    "           'org.datasyslab:geotools-wrapper:1.7.1-28.5'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f70d92be-4030-44fd-9c4d-02ca8c6658d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sedona.spark import *\n",
    "\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f94396f6-8b64-4dcb-8667-343daa1505b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset_storage_account_name=\"melikadatabricksstorage\"\n",
    "dataset_container_name=\"geospatial-dataset\"\n",
    "dataset_dir=\"raster/netcdf/global\"\n",
    "# dataset_file=\"pr_day_UKESM1-0-LL_ssp126_r1i1p1f2_gn_2015.nc\"\n",
    "dataset_file=\"tos_O1_2001-2002.nc\"\n",
    "# dataset_file=\"IMERG_land_sea_mask.nc\"\n",
    "# dataset_file=\"timeseries-tas-annual-mean_era5-x0.25_era5-x0.25-historical_timeseries_mean_1950-2022.nc\"\n",
    "nc_variable = \"tos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9df02885-c822-4267-b2e1-c20bc0c82367",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = sedona.read.format(\"binaryFile\").load(f\"abfss://{dataset_container_name}@{dataset_storage_account_name}.dfs.core.windows.net/{dataset_dir}/{dataset_file}\")\n",
    "df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d82673f-f7e1-41ed-aa40-2a62557d9024",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "record_info_row = df.selectExpr(\"RS_NetCDFInfo(content) as record_info\").first()\n",
    "print(record_info_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17a9e770-a9c2-45af-875d-8b47cb49e1b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df_raster = df.withColumn(\"raster\", expr(f\"RS_FromNetCDF(content, '{nc_variable}')\"))\n",
    "display(df_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bf77dc5-8414-4454-8a3c-c949b5b1fb73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "htmlDF = df_raster.selectExpr(\"RS_AsImage(raster, 500) as raster_image\")\n",
    "SedonaUtils.display_image(htmlDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19dea024-4f76-4b3b-a5a3-6e6539b088d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_num = df_raster.withColumn(\"num_raster\", expr(\"RS_NumBands(raster)\"))\n",
    "num_bands = df_num.select(\"num_raster\").first()[0]\n",
    "print(num_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51cfe249-5a4a-46cf-a1bc-1222fecc1149",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_raster.selectExpr(\n",
    "  \"explode(array(RS_Value(raster, 45, 65, 1))) as exploded\"\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cb14df4-68c9-466c-a1e7-536e6c5a6c76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pixels_as_geom = df_raster.selectExpr(\n",
    "  \"explode(RS_PixelAsCentroids(raster, 1)) as exploded\"\n",
    ").selectExpr(\n",
    "  \"exploded.geom as geom\",\n",
    "  \"exploded.x as x\",\n",
    "  \"exploded.y as y\"\n",
    ")\n",
    "\n",
    "df_pixels_as_geom.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a59fb681-27ee-4660-953d-56181eec0d89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Function to process each band and return a DataFrame\n",
    "def process_band(df_raster: DataFrame, band: int) -> DataFrame:\n",
    "    return df_raster.selectExpr(f\"explode_outer(RS_PixelAsPolygons(raster, {band})) as band\") \\\n",
    "                    .selectExpr(\"band.geom as geom\", \"band.value as band_value\", \"band.x as x\", \"band.y as y\") \\\n",
    "                    .where(\"band_value != 100000002004087734272\")\\\n",
    "                    .repartition(100)\n",
    "\n",
    "# Process the first band\n",
    "band1_df = process_band(df_raster, 1).withColumnRenamed(\"band_value\", \"band_1\")\n",
    "\n",
    "# Iterate over bands 2 to 24 and join their values\n",
    "for band in range(2, num_bands + 1):\n",
    "    band_df = process_band(df_raster, band).drop(\"geom\")\n",
    "    band1_df = band1_df.join(band_df, on=[\"x\", \"y\"], how=\"inner\") \\\n",
    "                       .withColumnRenamed(\"band_value\", f\"band_{band}\")\n",
    "\n",
    "display(band1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcfbc2c6-ec3c-4ad5-b871-323304b18822",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "band1_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fec027c9-f0d0-42ce-97ca-956331be9f3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "band_cols = [f\"band_{i}\" for i in range(1, num_bands+1)]\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_stats = filtered_df.withColumn(\"band_mean\", F.expr(f\"aggregate(array({', '.join(band_cols)}), 0D, (acc, x) -> acc + x) / {len(band_cols)}\")) \\\n",
    "             .withColumn(\"band_stddev\", F.expr(f\"\"\"sqrt(\n",
    "                 aggregate(array({', '.join(band_cols)}), 0D, (acc, x) -> acc + pow(x - band_mean, 2)) / {len(band_cols)}\n",
    "             )\"\"\")) \\\n",
    "             .withColumn(\"band_min\", F.least(*band_cols)) \\\n",
    "             .withColumn(\"band_max\", F.greatest(*band_cols))\n",
    "\n",
    "df_stats.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2a93936-7f84-43a9-bca0-c65a7cd94419",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def compute_percentile(values, percentile):\n",
    "    return float(np.percentile(values, percentile))\n",
    "\n",
    "percentile_udf = udf(lambda row: compute_percentile(row, 25), DoubleType())\n",
    "df_stats = df_stats.withColumn(\"band_p25\", percentile_udf(F.array(*band_cols)))\n",
    "\n",
    "percentile_udf = udf(lambda row: compute_percentile(row, 50), DoubleType())\n",
    "df_stats = df_stats.withColumn(\"band_p50\", percentile_udf(F.array(*band_cols)))\n",
    "\n",
    "percentile_udf = udf(lambda row: compute_percentile(row, 75), DoubleType())\n",
    "df_stats = df_stats.withColumn(\"band_p75\", percentile_udf(F.array(*band_cols)))\n",
    "\n",
    "df_stats = df_stats.repartition(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "456d4e02-23bd-4a5d-9724-a8a1fd77737d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_stats.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abbb4afd-6cd7-4305-a8de-244927f77fdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_stats.write.format(\"geojson\").save(\n",
    "    f\"abfss://{dataset_container_name}@{dataset_storage_account_name}.dfs.core.windows.net/{dataset_dir}/{nc_variable}.geojson\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05-NetCDF",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
