{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "403ea9ab-4804-4ed2-ae3a-e0d32857e3b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import expr, explode, col\n",
    "from sedona.spark import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "import math\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from osgeo import gdal, gdalconst\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57543734-4449-41ce-ab82-4175973cad05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset_bucket_name = \"revodata-databricks-geospatial\"\n",
    "file_urls = {\"2022\": f\"s3://{dataset_bucket_name}/geospatial-dataset/raster/orthophoto/soma/2022/2022_4BandImagery_SanFranciscoCA_J1191044.tif\", \"2025\": f\"s3://{dataset_bucket_name}/geospatial-dataset/raster/orthophoto/soma/2025/2025_4BandImagery_SanFranciscoCA_J1191043.tif\"}\n",
    "catalog_name = \"geospatial\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "522ce534-bae3-42f2-8dfa-61fc55f82499",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID'] = dbutils.secrets.get(scope=\"aws_geospatial_s3\", key=\"access_key\")\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = dbutils.secrets.get(scope=\"aws_geospatial_s3\", key=\"secret_key\")\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'eu-west-2'      # Match your bucket region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7a34ae5-39d5-40f6-9c70-3115ca5f2b25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config = SedonaContext.builder(). \\\n",
    "    config(\"spark.hadoop.fs.s3a.bucket.wherobots-examples.aws.credentials.provider\",\"org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider\"). \\\n",
    "    getOrCreate()\n",
    "\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80b4075c-dd03-4763-b3b3-eaa3f4c1326d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configure GDAL\n",
    "gdal.UseExceptions()\n",
    "gdal.SetConfigOption('GDAL_DISABLE_READDIR_ON_OPEN', 'YES')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_s3_client():\n",
    "    \"\"\"Initialize and return boto3 S3 client with credentials\"\"\"\n",
    "    return boto3.client('s3',\n",
    "                       aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "                       aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),\n",
    "                       region_name=os.getenv('AWS_DEFAULT_REGION', 'eu-west-2'))\n",
    "\n",
    "def upload_to_s3(local_path, s3_path):\n",
    "    \"\"\"Upload file to S3 using boto3\"\"\"\n",
    "    s3 = get_s3_client()\n",
    "    try:\n",
    "        bucket, key = s3_path.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "        s3.upload_file(local_path, bucket, key)\n",
    "        logger.info(f\"Successfully uploaded to {s3_path}\")\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        logger.error(f\"Failed to upload to S3: {e}\")\n",
    "        return False\n",
    "\n",
    "def merge_tiffs(binary_df, output_path):\n",
    "    \"\"\"\n",
    "    Merges multiple TIFF binary data from a Spark DataFrame into a single TIFF using GDAL\n",
    "    \n",
    "    Args:\n",
    "        binary_df: PySpark DataFrame containing binary TIFF data\n",
    "        output_path: Path to save the merged TIFF file (can be local or S3 path)\n",
    "    \"\"\"\n",
    "    # Collect all TIFF binary data to driver\n",
    "    tiff_data = binary_df.select(col(\"raster_binary\")).collect()\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp_files = []\n",
    "        \n",
    "        # Write each binary TIFF to a temporary file\n",
    "        for i, row in enumerate(tiff_data):\n",
    "            temp_file = os.path.join(temp_dir, f\"temp_{i}.tif\")\n",
    "            with open(temp_file, 'wb') as f:\n",
    "                f.write(row['raster_binary'])\n",
    "            temp_files.append(temp_file)\n",
    "        \n",
    "        if len(temp_files) > 0:\n",
    "            try:\n",
    "                # Create VRT mosaic\n",
    "                vrt_file = os.path.join(temp_dir, \"mosaic.vrt\")\n",
    "                gdal.BuildVRT(vrt_file, temp_files)\n",
    "                \n",
    "                # Create local output file\n",
    "                local_output = os.path.join(temp_dir, \"merged_output.tif\")\n",
    "                translate_options = gdal.TranslateOptions(\n",
    "                    creationOptions=['COMPRESS=DEFLATE', 'TILED=YES', 'BIGTIFF=IF_SAFER']\n",
    "                )\n",
    "                gdal.Translate(local_output, vrt_file, options=translate_options)\n",
    "                \n",
    "                # Handle output destination\n",
    "                if output_path.startswith('s3://'):\n",
    "                    if upload_to_s3(local_output, output_path):\n",
    "                        logger.info(f\"Merged {len(temp_files)} TIFFs to {output_path}\")\n",
    "                    else:\n",
    "                        raise Exception(\"Failed to upload to S3\")\n",
    "                else:\n",
    "                    os.rename(local_output, output_path)\n",
    "                    logger.info(f\"Merged {len(temp_files)} TIFFs to {output_path}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error during merge: {e}\")\n",
    "                raise\n",
    "        else:\n",
    "            logger.warning(\"No TIFF files found to merge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a2a7c2e-8908-444c-8ab0-34b8f8e89ccd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_image_2025 = sedona.read.format(\"binaryFile\").load(file_urls[\"2025\"])\n",
    "df_image_2025 = df_image_2025.withColumn(\"raster\", f.expr(\"RS_FromGeoTiff(content)\"))\n",
    "df_image_2025.createOrReplaceTempView(\"image_new_vw\")\n",
    "display(df_image_2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8b2e6f2-28f9-4dcb-8439-b72967b051d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(\"\"\"SELECT RS_MetaData(raster) AS metadata, \n",
    "                  RS_NumBands(raster) AS num_bands,\n",
    "                  RS_SummaryStatsAll(raster) AS summary_stat,\n",
    "                  RS_BandPixelType(raster) AS band_pixel_type,\n",
    "                  RS_Count(raster) AS count \n",
    "                  FROM image_new_vw\"\"\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99cc3dba-29af-4153-8a7f-a39b96a46e7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "htmlDf = sedona.sql(\"SELECT RS_AsImage(raster, 500) FROM image_new_vw\")\n",
    "SedonaUtils.display_image(htmlDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1b96bf2-a5a1-4b77-aa4e-14509ddf98bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_image_2022 = sedona.read.format(\"binaryFile\").load(file_urls[\"2022\"])\n",
    "df_image_2022 = df_image_2022.withColumn(\"raster\", f.expr(\"RS_FromGeoTiff(content)\"))\n",
    "df_image_2022.createOrReplaceTempView(\"image_old_vw\")\n",
    "display(df_image_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8598d813-5cde-482a-9222-49cc41625d7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def compute_tile_grid(w, h, x, y):\n",
    "    \"\"\"\n",
    "    Compute the optimal number of columns and rows to divide an image of size (w x h)\n",
    "    into tiles such that each tile is at least size x and at most size y in both width and height.\n",
    "    \n",
    "    Returns:\n",
    "        cols (int): number of tiles along width\n",
    "        rows (int): number of tiles along height\n",
    "        tile_width (int): actual width of each tile\n",
    "        tile_height (int): actual height of each tile\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_tile_count(dim, min_tile_size, max_tile_size):\n",
    "        # Get range of possible tile counts satisfying both size constraints\n",
    "        min_count = math.ceil(dim / max_tile_size)\n",
    "        max_count = math.floor(dim / min_tile_size)\n",
    "        if min_count > max_count:\n",
    "            raise ValueError(f\"Cannot tile dimension {dim} within bounds {min_tile_size}-{max_tile_size}\")\n",
    "        \n",
    "        # Choose the tile count that makes tiles closest to the center of the allowed range\n",
    "        best_count = None\n",
    "        best_tile_size = None\n",
    "        target_size = (min_tile_size + max_tile_size) / 2\n",
    "        \n",
    "        for count in range(min_count, max_count + 1):\n",
    "            tile_size = dim / count\n",
    "            if min_tile_size <= tile_size <= max_tile_size:\n",
    "                if best_tile_size is None or abs(tile_size - target_size) < abs(best_tile_size - target_size):\n",
    "                    best_tile_size = tile_size\n",
    "                    best_count = count\n",
    "                    \n",
    "        return best_count, math.ceil(dim / best_count)\n",
    "\n",
    "    cols, tile_width = get_tile_count(w, x, y)\n",
    "    rows, tile_height = get_tile_count(h, x, y)\n",
    "\n",
    "    return cols, rows, tile_width, tile_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b61d597-f84b-4cc9-90b5-820a4fcb2bb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "w = spark.sql(\"select RS_Width(raster) from image_new_vw\").collect()[0][0]\n",
    "h = spark.sql(\"select RS_Height(raster) from image_new_vw\").collect()[0][0]\n",
    "\n",
    "print(w)\n",
    "print(h)\n",
    "\n",
    "min_tile_size = 128  # minimum tile size\n",
    "max_tile_size = 256  # maximum tile size\n",
    "cols, rows, tile_w, tile_h = compute_tile_grid(w, h, min_tile_size, max_tile_size)\n",
    "print(f\"Image will be divided into {cols} columns and {rows} rows\")\n",
    "print(f\"Each tile will be approximately {tile_w} x {tile_h} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "047c6dd9-f69c-47b5-970a-d3e170a4aea8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tiled_df_2025 = df_image_2025.selectExpr(\n",
    "  f\"RS_TileExplode(raster, {tile_w}, {tile_h})\"\n",
    ").withColumnRenamed(\"x\", \"tile_x\").withColumnRenamed(\"y\", \"tile_y\").withColumn(\"width\", expr(\"RS_Width(tile)\")).withColumn(\"height\", expr(\"RS_height(tile)\"))\n",
    "window_spec = Window.orderBy(\"tile_x\", \"tile_y\")\n",
    "tiled_df_2025 = tiled_df_2025.withColumn(\"rn\", F.row_number().over(window_spec)).withColumn(\"year\", lit(2025))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0667e6bb-82a0-4d96-b1d0-7f0de4696091",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tiled_df_2022 = df_image_2022.selectExpr(\n",
    "  f\"RS_TileExplode(raster, {tile_w}, {tile_h})\"\n",
    ").withColumnRenamed(\"x\", \"tile_x\").withColumnRenamed(\"y\", \"tile_y\").withColumn(\"width\", expr(\"RS_Width(tile)\")).withColumn(\"height\", expr(\"RS_height(tile)\"))\n",
    "window_spec = Window.orderBy(\"tile_x\", \"tile_y\")\n",
    "tiled_df_2022 = tiled_df_2022.withColumn(\"rn\", F.row_number().over(window_spec)).withColumn(\"year\", lit(2022))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a56bf1cf-beba-406e-8ae3-af926b90aa8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "first_tile = tiled_df_2025.limit(1)\n",
    "first_tile.createOrReplaceTempView(\"first_tile_vw\")\n",
    "htmlDf = sedona.sql(\"SELECT RS_AsImage(tile) FROM first_tile_vw\")\n",
    "SedonaUtils.display_image(htmlDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43abb5b1-475d-4b4f-a16e-7cc0fc11a7f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "union_raster = tiled_df_2022.unionByName(tiled_df_2025, allowMissingColumns=False)\n",
    "window_spec = Window.partitionBy(\"rn\").orderBy(F.desc(\"year\"))\n",
    "union_raster = union_raster.withColumn(\"index\", F.row_number().over(window_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e867a0f-b598-4fcc-9797-4c1e86f4ae64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculating NDVI using Red and NIR bands as NDVI = (NIR - Red) / (NIR + Red)\n",
    "union_raster = union_raster.withColumn(\n",
    "    \"ndvi\",\n",
    "    expr(\n",
    "        \"RS_Divide(\"\n",
    "        \"  RS_Subtract(RS_BandAsArray(tile, 1), RS_BandAsArray(tile, 4)), \"\n",
    "        \"  RS_Add(RS_BandAsArray(tile, 1), RS_BandAsArray(tile, 4))\"\n",
    "        \")\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23b45178-fd73-4800-a34d-310a9458c124",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculating NDWI using Green and NIR bands as NDWI = (Green - NIR) / (Green + NIR)\n",
    "union_raster = union_raster.withColumn(\n",
    "    \"ndwi\",\n",
    "    expr(\n",
    "        \"RS_Divide(\"\n",
    "        \"  RS_Subtract(RS_BandAsArray(tile, 4), RS_BandAsArray(tile, 2)), \"\n",
    "        \"  RS_Add(RS_BandAsArray(tile, 4), RS_BandAsArray(tile, 2))\"\n",
    "        \")\"\n",
    "    )\n",
    ")\n",
    "\n",
    "display(union_raster.limit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44e009a7-0db3-4e16-b432-f3b23674a8f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Red and Green bands as arrays in new columns\n",
    "union_raster = union_raster.withColumn(\n",
    "    \"red\",\n",
    "    expr(\n",
    "        \"RS_BandAsArray(tile, 1)\"\n",
    "    )\n",
    ").withColumn(\n",
    "    \"green\",\n",
    "    expr(\n",
    "        \"RS_BandAsArray(tile, 2)\"\n",
    "    )\n",
    ")\n",
    "\n",
    "display(union_raster.limit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32b721bf-3286-40e1-8d1e-ea404d1d899f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Classification tree based on Red and Green bands and NDVI, NDWI\n",
    "union_raster = union_raster.withColumn(\n",
    "    \"classification\",\n",
    "    F.expr(\"\"\"\n",
    "        transform(\n",
    "            arrays_zip(ndvi, ndwi, red, green),\n",
    "            x -> \n",
    "                CASE \n",
    "                    WHEN year = 2022 THEN\n",
    "                        CASE \n",
    "                            WHEN x.red < 15 AND x.green < 15 THEN 4\n",
    "                            WHEN x.ndvi > 0.35 AND x.ndwi < -0.35 THEN 2\n",
    "                            WHEN (x.ndvi < -0.2 AND x.ndwi > 0.35) OR (x.red < 15 AND x.ndwi > 0.35) OR (x.ndwi > 0.45) THEN 3\n",
    "                            WHEN x.ndvi >= -0.3 AND x.ndvi <= 0.3 AND x.ndwi >= -0.3 AND x.ndwi <= 0.3 THEN 1\n",
    "                            ELSE 999\n",
    "                        END\n",
    "                    WHEN year = 2025 THEN\n",
    "                        CASE \n",
    "                            WHEN x.red < 15 AND x.green < 15 THEN 4\n",
    "                            WHEN x.ndvi > 0.3 AND x.ndwi < -0.15 THEN 2\n",
    "                            WHEN x.ndvi < -0.35 AND x.ndwi > 0.55 THEN 3\n",
    "                            WHEN (x.ndvi >= -0.5 AND x.ndvi <= 0.5 AND x.ndwi >= -0.5 AND x.ndwi <= 0.5) OR (x.ndvi > 0.8 AND x.ndwi > 0.3) THEN 1                           \n",
    "                            ELSE 999\n",
    "                        END\n",
    "                    ELSE 999\n",
    "                END\n",
    "        )\n",
    "    \"\"\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78e59283-e1a2-47f9-8063-5cce9e724c2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(union_raster.limit(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14c730da-e0e4-482e-b3cb-66fae610577a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Classification array as a new band in the raster and defining no data value as 999 \n",
    "classification_df = (\n",
    "    union_raster\n",
    "    .select(\"tile_x\", \"tile_y\", \"rn\", \"year\", \"index\", expr(\"RS_MakeRaster(tile, 'I', classification) AS tile\").alias(\"tile\"))\n",
    "    .select(\"tile_x\", \"tile_y\", \"rn\", \"year\", \"index\", expr(\"RS_SetBandNoDataValue(tile,1, 999, false)\").alias(\"tile\"))\n",
    "    .select(\"tile_x\", \"tile_y\", \"rn\", \"year\", \"index\", expr(\"RS_SetBandNoDataValue(tile,1, 999, true)\").alias(\"tile\"))\n",
    ")\n",
    "display(classification_df.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4de69bcd-98f2-4bce-b6a2-a6114f8f04c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "classification_df.withColumn(\"raster_binary\", expr(\"RS_AsGeoTiff(tile)\")).select(\"tile_x\", \"tile_y\",\"rn\", \"year\", \"index\", \"raster_binary\").write.mode(\"overwrite\").saveAsTable(\"geospatial.soma.classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "916dec3b-87ee-4716-8385-ba4c6705c821",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(classification_df.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbc1f69e-9053-4df0-b240-dc670b3aa655",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "geotiff_df = spark.table(\"geospatial.soma.classification\").repartitionByRange(10,\"rn\")\n",
    "display(geotiff_df.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a92cbe2-0033-433b-9e32-23b2ac7bba7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Merge TIFFs\n",
    "output_tiff_2025 = f\"s3://{dataset_bucket_name}/geospatial-dataset/raster/orthophoto/soma/classification/classification_2025.tif\"\n",
    "output_tiff_2022 = f\"s3://{dataset_bucket_name}/geospatial-dataset/raster/orthophoto/soma/classification/classification_2022.tif\"\n",
    "\n",
    "class_2025 = geotiff_df.filter(geotiff_df[\"year\"] == 2025)\n",
    "class_2022 = geotiff_df.filter(geotiff_df[\"year\"] == 2022)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa928aea-07cd-487f-b8fa-e91bb8723a03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merge_tiffs(class_2025, output_tiff_2025)\n",
    "merge_tiffs(class_2022, output_tiff_2022)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4248342033090984,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "06-raster-change-detection-classification",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
