{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4125ee83-a41b-41b0-b36a-d3b4ed0d3072",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sedona.spark import *\n",
    "from sedona.maps.SedonaPyDeck import SedonaPyDeck\n",
    "from sedona.maps.SedonaKepler import SedonaKepler\n",
    "from pyspark.sql import functions as F\n",
    "from sedona.sql import st_functions as st\n",
    "from sedona.sql.types import GeometryType\n",
    "from pyspark.sql.functions import expr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a750331-95a3-4dab-b36a-8f98ba8f188e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config = SedonaContext.builder() .\\\n",
    "    config('spark.jars.packages',\n",
    "           'org.apache.sedona:sedona-spark-shaded-3.3_2.12:1.7.1,'\n",
    "           'org.datasyslab:geotools-wrapper:1.7.1-28.5'). \\\n",
    "    getOrCreate()\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e8f9727-79fd-447e-b499-8264dde4e174",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def transform_geometry_sql(df, geometry_col=\"geometry\", temp_view_name=\"input_geometries\"):\n",
    "    \"\"\"\n",
    "    Transforms a Spark DataFrame by:\n",
    "    - Removing the geometry column from output\n",
    "    - Adding derived columns: geometry_ewkb, xmin, xmax, ymin, ymax using Sedona SQL\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): Input Spark DataFrame with a geometry column of GeometryType\n",
    "    - geometry_col (str): Name of the geometry column (default: \"geometry\")\n",
    "    - temp_view_name (str): Temporary view name to use in SQL (default: \"input_geometries\")\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Transformed DataFrame ready for write\n",
    "    \"\"\"\n",
    "    # Register temporary view\n",
    "    df.createOrReplaceTempView(temp_view_name)\n",
    "\n",
    "    # Get all columns except the geometry column\n",
    "    cols_to_select = [col for col in df.columns if col != geometry_col]\n",
    "    select_expr = \",\\n       \".join(cols_to_select)\n",
    "\n",
    "    # Construct SQL query\n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        {select_expr},\n",
    "        ST_AsEWKB({geometry_col}) AS geometry,\n",
    "        ST_XMin({geometry_col}) AS xmin,\n",
    "        ST_XMax({geometry_col}) AS xmax,\n",
    "        ST_YMin({geometry_col}) AS ymin,\n",
    "        ST_YMax({geometry_col}) AS ymax\n",
    "    FROM {temp_view_name}\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute SQL and return the result\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cb7d875-67f5-41e1-8502-fab2d716022f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "road_nodes_silver = spark.sql(\"\"\"\n",
    "SELECT a.fid, a.id, a.form_of_road_node, COUNT(DISTINCT b.id) AS degree, ST_GeomFromEWKB(a.geometry) AS geometry, ST_Geohash(ST_Transform(ST_GeomFromEWKB(a.geometry),'epsg:27700','epsg:4326'), 5) AS geohash \n",
    "FROM geospatial.networks.road_node a\n",
    "JOIN geospatial.networks.road_link b\n",
    "ON a.id = b.start_node\n",
    "OR a.id = b.end_node\n",
    "GROUP BY a.fid, a.id, a.form_of_road_node, a.geometry\n",
    "ORDER BY COUNT(DISTINCT b.id) DESC\"\"\").repartitionByRange(2, \"geohash\")\n",
    "\n",
    "road_nodes_silver.createOrReplaceTempView(\"road_nodes_silver_vw\")\n",
    "road_nodes_silver.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a43be0c-286e-4877-af8b-8770b71a1522",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_road_nodes_ewkb = transform_geometry_sql(road_nodes_silver)\n",
    "df_road_nodes_ewkb.write.mode(\"overwrite\").saveAsTable(f\"geospatial.networks.road_node_silver\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6520815512823086,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "03-prepare-silver_roads",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
