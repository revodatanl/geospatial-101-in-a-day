{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af8938e2-eec0-445d-9e91-c65007bc26aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Dynamically resolve notebook path\n",
    "notebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "notebook_dir = \"/Workspace\" + os.path.dirname(notebook_path)\n",
    "\n",
    "# Assuming src is a sibling of notebooks\n",
    "src_path = os.path.abspath(os.path.join(notebook_dir, \"..\", \"src\"))\n",
    "print(src_path)\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7151cf7-860f-44b1-b78f-01da1b1f70f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset_storage_account_name=\"melikadatabricksstorage\"\n",
    "dataset_container_name=\"geospatial-dataset\"\n",
    "dataset_input_dir=\"vector/uk\"\n",
    "dataset_output_dir=\"vector/uk\"\n",
    "\n",
    "catalog_storage_account_name = \"melikadatabricksstorage\"\n",
    "catalog_container_name = \"geospatial-catalog\"\n",
    "catalog_name = \"geospatial\"\n",
    "schema_names = [\"greenspaces\", \"heights\", \"lookups\", \"networks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39f6cb48-bd97-46e1-8743-f1e1ed1cbf3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(f\"spark.hadoop.fs.azure.account.auth.type.{dataset_storage_account_name}.dfs.core.windows.net\", \"ManagedIdentity\")\n",
    "spark.conf.set(f\"spark.hadoop.fs.azure.account.oauth2.client.id.{dataset_storage_account_name}.dfs.core.windows.net\",\"a6d7d9b6-d9a1-4711-a74b-3cdfc43f3dd8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51a3483a-1ef2-4fd9-9461-5ab2a8e1cac5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import from your package\n",
    "from geo_ingest.geopackage_unzipper import GeoPackageUnzipper\n",
    "\n",
    "# Set up and run the unzipper\n",
    "unzipper = GeoPackageUnzipper(\n",
    "    storage_account_name=dataset_storage_account_name,\n",
    "    container_name=dataset_container_name,\n",
    "    input_dir=dataset_input_dir,\n",
    "    output_dir=dataset_output_dir,\n",
    "    dbutils= dbutils\n",
    ")\n",
    "\n",
    "zip_files = [\"bdline_gpkg_gb.zip\", \"opgrsp_gpkg_gb.zip\", \"opname_gpkg_gb.zip\", \"oproad_gpkg_gb.zip\", \"oprvrs_gpkg_gb.zip\", \"terr50_gpkg_gb.zip\"]\n",
    "unzipper.unzip_selected_and_upload(zip_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abac4040-4f7b-49e8-bb74-bb44b3af0c5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for item in schema_names:\n",
    "    drop_query = f\"\"\"\n",
    "        DROP SCHEMA IF EXISTS {catalog_name}.{item} CASCADE;\n",
    "        \"\"\";\n",
    "    spark.sql(drop_query)\n",
    "\n",
    "    create_query = f\"\"\"\n",
    "        CREATE SCHEMA IF NOT EXISTS {catalog_name}.{item}\n",
    "        COMMENT 'This schema contains {item} data of the UK'\n",
    "        MANAGED LOCATION 'abfss://{catalog_container_name}@{catalog_storage_account_name}.dfs.core.windows.net/';\n",
    "        \"\"\";\n",
    "\n",
    "    spark.sql(create_query)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00-initialize",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
