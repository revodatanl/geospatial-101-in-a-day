{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4125ee83-a41b-41b0-b36a-d3b4ed0d3072",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sedona.spark import *\n",
    "from sedona.maps.SedonaPyDeck import SedonaPyDeck\n",
    "from sedona.maps.SedonaKepler import SedonaKepler\n",
    "from pyspark.sql import functions as F\n",
    "from sedona.sql import st_functions as st\n",
    "from sedona.sql.types import GeometryType\n",
    "from pyspark.sql.functions import expr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a750331-95a3-4dab-b36a-8f98ba8f188e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config = SedonaContext.builder() .\\\n",
    "    config('spark.jars.packages',\n",
    "           'org.apache.sedona:sedona-spark-shaded-3.3_2.12:1.7.1,'\n",
    "           'org.datasyslab:geotools-wrapper:1.7.1-28.5'). \\\n",
    "    getOrCreate()\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e8f9727-79fd-447e-b499-8264dde4e174",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def transform_geometry_sql(df, geometry_col=\"geometry\", temp_view_name=\"input_geometries\"):\n",
    "    \"\"\"\n",
    "    Transforms a Spark DataFrame by:\n",
    "    - Removing the geometry column from output\n",
    "    - Adding derived columns: geometry_ewkb, xmin, xmax, ymin, ymax using Sedona SQL\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): Input Spark DataFrame with a geometry column of GeometryType\n",
    "    - geometry_col (str): Name of the geometry column (default: \"geometry\")\n",
    "    - temp_view_name (str): Temporary view name to use in SQL (default: \"input_geometries\")\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Transformed DataFrame ready for write\n",
    "    \"\"\"\n",
    "    # Register temporary view\n",
    "    df.createOrReplaceTempView(temp_view_name)\n",
    "\n",
    "    # Get all columns except the geometry column\n",
    "    cols_to_select = [col for col in df.columns if col != geometry_col]\n",
    "    select_expr = \",\\n       \".join(cols_to_select)\n",
    "\n",
    "    # Construct SQL query\n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        {select_expr},\n",
    "        ST_AsEWKB({geometry_col}) AS geometry,\n",
    "        ST_XMin({geometry_col}) AS xmin,\n",
    "        ST_XMax({geometry_col}) AS xmax,\n",
    "        ST_YMin({geometry_col}) AS ymin,\n",
    "        ST_YMax({geometry_col}) AS ymax\n",
    "    FROM {temp_view_name}\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute SQL and return the result\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ede4b24-e076-4b67-a189-662ee63ca688",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "administrative_boundaries  = spark.sql(\"\"\"\n",
    "  SELECT b.fid, b.name, ST_Area(ST_GeomFromEWKB(b.geometry)) AS area, ST_GeomFromEWKB(geometry) AS geometry, ST_Geohash(ST_Transform(ST_GeomFromEWKB(geometry),'epsg:27700','epsg:4326'), 5) AS geohash\n",
    "  FROM geospatial.lookups.boundary_line_ceremonial_counties b \n",
    "\"\"\").repartitionByRange(2, \"geohash\")\n",
    "\n",
    "\n",
    "num_partitions = administrative_boundaries.rdd.getNumPartitions()\n",
    "print(f\"DataFrame has {num_partitions} partitions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5b048b4-3261-4fe5-aa13-d089048620ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE EXTENDED geospatial.lookups.boundary_line_ceremonial_counties;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32b7348f-5b2e-46df-a8a5-7fde97c9547f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total_allocations = 1000\n",
    "\n",
    "uk_arae = administrative_boundaries.selectExpr(\"SUM(area) AS total_area\").first().total_area\n",
    "\n",
    "administrative_boundaries = administrative_boundaries.withColumn(\n",
    "    \"number_of_allocations\",\n",
    "    F.round(F.col(\"area\") / uk_arae * F.lit(total_allocations)).cast(\"integer\")\n",
    ").orderBy(\"number_of_allocations\", ascending=True)\n",
    "\n",
    "administrative_boundaries.createOrReplaceTempView(\"administrative_boundaries_vw\")\n",
    "administrative_boundaries.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1acae786-b2f9-484f-8767-266768d19714",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "administrative_boundaries.selectExpr(\"SUM(number_of_allocations) AS num_allocations\").first().num_allocations\n",
    "\n",
    "display(administrative_boundaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc54063e-4501-4b61-b267-7a9ba598cfea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "administrative_boundaries.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78a2077f-50a0-4c0b-80ba-b5d21d96afa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_county_ewkb = transform_geometry_sql(administrative_boundaries)\n",
    "df_county_ewkb.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(f\"geospatial.lookups.boundary_line_ceremonial_counties_silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5d410dd-5e42-4201-b72d-732248d272cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT SUM(number_of_allocations) FROM geospatial.lookups.boundary_line_ceremonial_counties_silver;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1563f77b-3f1c-401f-a24e-9b9b4865946d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# map = SedonaKepler.create_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db8e7176-268f-45c4-b9e6-a37b57151b65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SedonaKepler.add_df(map, administrative_boundaries, name=\"Cermonial Counties\")\n",
    "# map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27f4169c-d921-4e09-a986-145f51b0c14a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_greenspaces_bronze = spark.table(\"geospatial.greenspaces.greenspace_site\") \\\n",
    "    .filter(\"function IN ('Play Space', 'Playing Field', 'Public Park Or Garden')\").withColumn(\"geometry\", expr(\"ST_GeomFromEWKB(geometry)\"))\n",
    "df_greenspaces_bronze.createOrReplaceTempView(\"greenspace_site_bronze_vw\")\n",
    "df_greenspaces_bronze.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d5f0183-baab-479b-afbf-196e218f407a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "greenspace_site_covered = spark.sql(\"\"\"\n",
    "  SELECT \n",
    "    g1.id AS g1_id,\n",
    "    g2.id AS g2_id,\n",
    "    g1.function AS g1_function,\n",
    "    g2.function AS g2_function,\n",
    "    g2.distinctive_name_1 AS g2_name,\n",
    "    g2.geometry AS geometry,\n",
    "    ST_Geohash(ST_Transform(g2.geometry ,'epsg:27700','epsg:4326'), 5) AS geohash\n",
    "  FROM greenspace_site_bronze_vw g1\n",
    "  INNER JOIN greenspace_site_bronze_vw g2\n",
    "    ON ST_CoveredBy(g1.geometry, g2.geometry)\n",
    "   AND g1.id != g2.id\n",
    "\"\"\").repartitionByRange(2, \"geohash\")\n",
    "\n",
    "greenspace_site_covered.createOrReplaceTempView(\"greenspace_site_covered_vw\")\n",
    "greenspace_site_covered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f3408d4-9f96-4996-a43f-0d8c502fc544",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "greenspace_site_aggregated = spark.sql(\"\"\"\n",
    "  SELECT \n",
    "    g2_id AS id,\n",
    "    concat_ws(', ', any_value(g2_function), collect_set(g1_function)) AS functions,\n",
    "    count(*) + 1 AS num_functions,\n",
    "    g2_name AS name,\n",
    "    ST_Area(geometry) AS area,\n",
    "    geometry,\n",
    "    ST_Geohash(ST_Transform(geometry,'epsg:27700','epsg:4326'), 5) AS geohash\n",
    "  FROM greenspace_site_covered_vw\n",
    "  GROUP BY g2_id, g2_name, geometry\n",
    "\"\"\").repartitionByRange(2, \"geohash\")\n",
    "greenspace_site_aggregated.cache()\n",
    "greenspace_site_aggregated.createOrReplaceTempView(\"greenspace_site_aggregated_vw\")\n",
    "greenspace_site_aggregated.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2cb5e66-5627-4e48-a5f0-44c6ee315cce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "greenspace_site_non_covered = spark.sql(\"\"\"\n",
    "  SELECT id, function, 1 AS num_functions, distinctive_name_1 AS name, ST_Area(geometry) AS area, geometry,\n",
    "  ST_Geohash(ST_Transform(geometry,'epsg:27700','epsg:4326'), 5) AS geohash\n",
    "  FROM greenspace_site_bronze_vw\n",
    "  WHERE id NOT IN (SELECT g1_id FROM greenspace_site_covered_vw)\n",
    "    AND id NOT IN (SELECT g2_id FROM greenspace_site_covered_vw)\n",
    "\"\"\").repartitionByRange(42, \"geohash\")\n",
    "greenspace_site_non_covered.cache()\n",
    "greenspace_site_non_covered.createOrReplaceTempView(\"greenspace_site_non_covered_vw\")\n",
    "greenspace_site_non_covered.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d17c265-336e-4bcd-ae10-f2272455c742",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "greenspace_site_all = spark.sql(\"\"\"\n",
    "SELECT * FROM greenspace_site_aggregated_vw\n",
    "UNION\n",
    "SELECT * FROM greenspace_site_non_covered_vw\"\"\").repartitionByRange(2, \"geohash\")\n",
    "\n",
    "# Calculate 0%, 20%, 40%, 60%, 80%, 100% quantiles\n",
    "quantiles = greenspace_site_all.approxQuantile(\"area\", [0.0, 0.2, 0.4, 0.6, 0.8, 1.0], 0.001)\n",
    "print(\"Quintile breakpoints:\", quantiles)\n",
    "\n",
    "q0, q20, q40, q60, q80, q100 = quantiles\n",
    "\n",
    "greenspace_site_all = greenspace_site_all.withColumn(\n",
    "    \"area_category\",\n",
    "    F.when(F.col(\"area\") <= q20, 20)\n",
    "     .when(F.col(\"area\") <= q40, 40)\n",
    "     .when(F.col(\"area\") <= q60, 60)\n",
    "     .when(F.col(\"area\") <= q80, 80)\n",
    "     .otherwise(100)\n",
    ")\n",
    "\n",
    "\n",
    "greenspace_site_all.groupBy(\"area_category\").count().orderBy(\"area_category\").show()\n",
    "\n",
    "greenspace_site_all.cache()\n",
    "greenspace_site_all.createOrReplaceTempView(\"greenspace_site_all_vw\")\n",
    "greenspace_site_all.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a1c91ca-ed4a-4005-a4a9-21b0a07e17bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "greenspace_site_all.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c0d88eb-9a6f-4f05-819d-1343df9581df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "greenspace_site_silver = spark.sql(\"\"\"\n",
    "WITH tmp AS (\n",
    "SELECT a.id, a.functions, a.num_functions, a.name, a.area, a.area_category, a.geometry, a.geohash,\n",
    "RANK() OVER(PARTITION BY a.id ORDER BY ST_Area(ST_Intersection(a.geometry, b.geometry)) DESC) AS administrative_rank,\n",
    "b.fid as administrative_fid\n",
    "FROM greenspace_site_all_vw a\n",
    "INNER JOIN administrative_boundaries_vw b\n",
    "ON ST_Intersects(a.geometry, b.geometry))\n",
    "SELECT tmp.id, tmp.functions, tmp.num_functions, tmp.name, tmp.area, tmp.area_category, tmp.administrative_fid, tmp.geometry, tmp.geohash\n",
    "FROM tmp\n",
    "WHERE  administrative_rank = 1\n",
    "\"\"\").repartitionByRange(2, \"geohash\")\n",
    "\n",
    "greenspace_site_silver.cache()\n",
    "greenspace_site_silver.createOrReplaceTempView(\"greenspace_site_silver_vw\")\n",
    "greenspace_site_silver.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5901b05-c9ba-4598-810e-67ac24e847ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_gr_site_ewkb = transform_geometry_sql(greenspace_site_silver)\n",
    "df_gr_site_ewkb.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(f\"geospatial.greenspaces.greenspace_site_silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17a90704-6677-41c5-a2f3-1452d737b94a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "greenspace_entries = spark.sql(\"\"\"\n",
    "SELECT a.fid, a.id, a.access_type, a.ref_to_greenspace_site, ST_GeomFromEWKB(a.geometry) AS geometry, ST_Geohash(ST_Transform(ST_GeomFromEWKB(geometry),'epsg:27700','epsg:4326'), 5) AS geohash\n",
    "FROM geospatial.greenspaces.access_point a\n",
    "WHERE a.ref_to_greenspace_site IN (SELECT id FROM greenspace_site_silver_vw)\"\"\").repartitionByRange(2, \"geohash\")\n",
    "\n",
    "greenspace_entries.createOrReplaceTempView(\"greenspace_entries_vw\")\n",
    "greenspace_entries.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cb7d875-67f5-41e1-8502-fab2d716022f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "road_nodes_silver = spark.sql(\"\"\"\n",
    "SELECT a.fid, a.id, a.form_of_road_node, COUNT(DISTINCT b.id) AS degree, ST_GeomFromEWKB(a.geometry) AS geometry, ST_Geohash(ST_Transform(ST_GeomFromEWKB(a.geometry),'epsg:27700','epsg:4326'), 5) AS geohash \n",
    "FROM geospatial.networks.road_node a\n",
    "JOIN geospatial.networks.road_link b\n",
    "ON a.id = b.start_node\n",
    "OR a.id = b.end_node\n",
    "GROUP BY a.fid, a.id, a.form_of_road_node, a.geometry\n",
    "ORDER BY COUNT(DISTINCT b.id) DESC\"\"\").repartitionByRange(2, \"geohash\")\n",
    "\n",
    "road_nodes_silver.createOrReplaceTempView(\"road_nodes_silver_vw\")\n",
    "road_nodes_silver.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a43be0c-286e-4877-af8b-8770b71a1522",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_road_nodes_ewkb = transform_geometry_sql(road_nodes_silver)\n",
    "df_road_nodes_ewkb.write.mode(\"overwrite\").saveAsTable(f\"geospatial.networks.road_node_silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41871907-ab03-4c82-90d2-004502893270",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "entry_road_1NN = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    a.fid,\n",
    "    a.id,\n",
    "    a.access_type,\n",
    "    a.ref_to_greenspace_site,\n",
    "    b.fid AS nearest_road_node_fid,\n",
    "    ST_Distance(a.geometry, b.geometry) AS distance_to_road_node,\n",
    "    a.geometry, \n",
    "    a.geohash\n",
    "FROM greenspace_entries_vw a \n",
    "INNER JOIN road_nodes_silver_vw b \n",
    "ON ST_kNN(a.geometry, b.geometry, 1, FALSE)\"\"\").repartitionByRange(2, \"geohash\")\n",
    "\n",
    "entry_road_1NN.createOrReplaceTempView(\"entry_road_1NN_vw\")\n",
    "entry_road_1NN.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9234042-e5ce-4546-b9c0-c0677996b020",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_1nn_ewkb = transform_geometry_sql(entry_road_1NN)\n",
    "df_1nn_ewkb.write.mode(\"overwrite\").saveAsTable(f\"geospatial.greenspaces.access_point_silver\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6520815512823086,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "03-prepare-silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
