{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "472b7349-25e8-483f-811c-c83b59f2aca5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Goal\n",
    "\n",
    "The purpose of this notebook is to implement the following business logic:\n",
    "\n",
    "- Determine the number of spots to allocate to each county based on its area.\n",
    "- Prioritize spot allocation near park entries, as BI dashboards indicate parks have the highest sales.\n",
    "- Favor larger parks with more functionalities (e.g., playgrounds, sport fields) as they are more attractive.\n",
    "- Prefer park entrances that are more accessible, as these are more desirable locations for spot allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fff6972-abd9-4d11-b25e-64268106276b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../get_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0a7eebd-8986-48db-8c52-4905c28d21b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_email = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "username = get_username_from_email(user_email)\n",
    "print(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4125ee83-a41b-41b0-b36a-d3b4ed0d3072",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32b7348f-5b2e-46df-a8a5-7fde97c9547f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This block calculates the total area of all UK ceremonial counties and allocates a proportional number of locations to each county based on its area.\n",
    "# It then orders the counties by the number of allocated locations and saves the result as a new silver table in Unity Catalog.\n",
    "\n",
    "administrative_boundaries = spark.sql(\n",
    "    f\"\"\"\n",
    "    SELECT \n",
    "        b.fid, \n",
    "        b.name, \n",
    "        ST_Area(b.geometry)::FLOAT AS area, \n",
    "        b.geometry, \n",
    "        ST_Geohash(ST_Transform(b.geometry, 4326), 5) AS geohash\n",
    "    FROM geospatial.lookups_geobrix.boundary_line_ceremonial_counties_{username} b\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "total_locations = 1000\n",
    "uk_area = administrative_boundaries.selectExpr(\"SUM(area) AS total_area\").first().total_area\n",
    "\n",
    "administrative_boundaries = (\n",
    "    administrative_boundaries.withColumn(\n",
    "        \"number_of_locations\",\n",
    "        F.round(F.col(\"area\") / uk_area * F.lit(total_locations)).cast(\"integer\")\n",
    "    )\n",
    "    .orderBy(\"number_of_locations\", ascending=True)\n",
    ")\n",
    "\n",
    "administrative_boundaries.write.mode(\"overwrite\").saveAsTable(\n",
    "    f\"geospatial.lookups_geobrix.boundary_line_ceremonial_counties_silver_{username}\"\n",
    ")\n",
    "\n",
    "administrative_boundaries.createOrReplaceTempView(\"administrative_boundaries_vw\")\n",
    "display(administrative_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d5f0183-baab-479b-afbf-196e218f407a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This block processes greenspace sites by:\n",
    "# 1. Filtering for relevant greenspace functions ('Play Space', 'Playing Field', 'Public Park Or Garden').\n",
    "# 2. Identifying and aggregating sites that are spatially covered by a larger greenspace site, combining their functions and counting the number of unique functions. This is an indicator of attrcativeness.\n",
    "# 3. Assigning area quantiles (20, 40, 60, 80, 100) to each site based on their area, to categorize them by size.\n",
    "# 4. Creating unified views for both aggregated and non-covered sites, and combining them into a single DataFrame for further analysis.\n",
    "# 5. Preparing the resulting DataFrame for downstream prioritization and allocation logic by exposing it as a temporary view.\n",
    "\n",
    "df_greenspaces_bronze = (\n",
    "    spark.table(f\"geospatial.greenspaces_geobrix.greenspace_site_{username}\")\n",
    "    .filter(\"function IN ('Play Space', 'Playing Field', 'Public Park Or Garden')\")\n",
    ")\n",
    "df_greenspaces_bronze.createOrReplaceTempView(\"greenspace_site_bronze_vw\")\n",
    "\n",
    "greenspace_site_covered = (\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            g1.id AS g1_id,\n",
    "            g2.id AS g2_id,\n",
    "            g1.function AS g1_function,\n",
    "            g2.function AS g2_function,\n",
    "            g2.distinctive_name_1 AS g2_name,\n",
    "            g2.geometry AS geometry,\n",
    "            ST_Geohash(ST_Transform(g2.geometry, 4326), 5) AS geohash\n",
    "        FROM greenspace_site_bronze_vw g1\n",
    "        INNER JOIN greenspace_site_bronze_vw g2\n",
    "            ON ST_Covers(g2.geometry, g1.geometry)\n",
    "            AND g1.id != g2.id\n",
    "    \"\"\")\n",
    "    .repartitionByRange(10, \"geohash\")\n",
    ")\n",
    "greenspace_site_covered.createOrReplaceTempView(\"greenspace_site_covered_vw\")\n",
    "\n",
    "greenspace_site_aggregated = (\n",
    "    spark.sql(\"\"\"\n",
    "        WITH tmp AS (\n",
    "            SELECT *, ST_AsEWKB(geometry) AS wkb_geometry\n",
    "            FROM greenspace_site_covered_vw\n",
    "        )\n",
    "        SELECT \n",
    "            g2_id AS id,\n",
    "            concat_ws(', ', any_value(g2_function), collect_set(g1_function)) AS functions,\n",
    "            count(*) + 1 AS num_functions,\n",
    "            g2_name AS name,\n",
    "            ST_Area(ST_SetSrid(ST_GeomFromEWKB(wkb_geometry),27700)) AS area,\n",
    "            ST_SetSrid(ST_GeomFromEWKB(wkb_geometry),27700) AS geometry,\n",
    "            ST_Geohash(ST_Transform(ST_SetSrid(ST_GeomFromEWKB(wkb_geometry),27700), 4326), 5) AS geohash\n",
    "        FROM tmp\n",
    "        GROUP BY g2_id, g2_name, wkb_geometry\n",
    "    \"\"\")\n",
    "    .repartitionByRange(10, \"geohash\")\n",
    ")\n",
    "greenspace_site_aggregated.createOrReplaceTempView(\"greenspace_site_aggregated_vw\")\n",
    "\n",
    "greenspace_site_non_covered = (\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            id, \n",
    "            function, \n",
    "            1 AS num_functions, \n",
    "            distinctive_name_1 AS name, \n",
    "            ST_Area(geometry) AS area, \n",
    "            geometry,\n",
    "            ST_Geohash(ST_Transform(geometry, 4326), 5) AS geohash\n",
    "        FROM greenspace_site_bronze_vw\n",
    "        WHERE id NOT IN (SELECT g1_id FROM greenspace_site_covered_vw)\n",
    "          AND id NOT IN (SELECT g2_id FROM greenspace_site_covered_vw)\n",
    "    \"\"\")\n",
    "    .repartitionByRange(10, \"geohash\")\n",
    ")\n",
    "greenspace_site_non_covered.createOrReplaceTempView(\"greenspace_site_non_covered_vw\")\n",
    "\n",
    "greenspace_site_all = (\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT * FROM greenspace_site_aggregated_vw\n",
    "        UNION ALL\n",
    "        SELECT * FROM greenspace_site_non_covered_vw\n",
    "    \"\"\")\n",
    "    .repartitionByRange(10, \"geohash\")\n",
    ")\n",
    "\n",
    "# Calculate 0%, 20%, 40%, 60%, 80%, 100% quantiles for area\n",
    "quantiles = greenspace_site_all.approxQuantile(\"area\", [0.0, 0.2, 0.4, 0.6, 0.8, 1.0], 0.001)\n",
    "print(\"Quintile breakpoints:\", quantiles)\n",
    "\n",
    "q0, q20, q40, q60, q80, q100 = quantiles\n",
    "\n",
    "greenspace_site_all = greenspace_site_all.withColumn(\n",
    "    \"area_category\",\n",
    "    F.when(F.col(\"area\") <= q20, 20)\n",
    "     .when(F.col(\"area\") <= q40, 40)\n",
    "     .when(F.col(\"area\") <= q60, 60)\n",
    "     .when(F.col(\"area\") <= q80, 80)\n",
    "     .otherwise(100)\n",
    ")\n",
    "\n",
    "display(greenspace_site_all.groupBy(\"area_category\").count().orderBy(\"area_category\"))\n",
    "greenspace_site_all.createOrReplaceTempView(\"greenspace_site_all_vw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c0d88eb-9a6f-4f05-819d-1343df9581df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This block assigns each greenspace to the administrative boundary (county) with which it has the largest area of intersection.\n",
    "# For each greenspace, it calculates the intersection area with all overlapping boundaries, ranks them, and selects the boundary with the maximum intersection.\n",
    "# The result is a silver table mapping greenspaces to their most representative administrative boundary.\n",
    "\n",
    "greenspace_site_silver = spark.sql(\"\"\"\n",
    "    WITH tmp AS (\n",
    "        SELECT \n",
    "            a.id, \n",
    "            a.functions, \n",
    "            a.num_functions, \n",
    "            a.name, \n",
    "            a.area, \n",
    "            a.area_category, \n",
    "            a.geometry, \n",
    "            a.geohash,\n",
    "            RANK() OVER (\n",
    "                PARTITION BY a.id \n",
    "                ORDER BY ST_Area(ST_Intersection(a.geometry, b.geometry)) DESC\n",
    "            ) AS administrative_rank,\n",
    "            b.fid AS administrative_fid\n",
    "        FROM greenspace_site_all_vw a\n",
    "        INNER JOIN administrative_boundaries_vw b\n",
    "            ON ST_Intersects(a.geometry, b.geometry)\n",
    "    )\n",
    "    SELECT \n",
    "        tmp.id, \n",
    "        tmp.functions, \n",
    "        tmp.num_functions, \n",
    "        tmp.name, \n",
    "        tmp.area, \n",
    "        tmp.area_category, \n",
    "        tmp.administrative_fid, \n",
    "        tmp.geometry, \n",
    "        tmp.geohash\n",
    "    FROM tmp\n",
    "    WHERE administrative_rank = 1\n",
    "\"\"\").repartitionByRange(10, \"geohash\")\n",
    "\n",
    "greenspace_site_silver.createOrReplaceTempView(\"greenspace_site_silver_vw\")\n",
    "greenspace_site_silver.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\n",
    "    f\"geospatial.greenspaces_geobrix.greenspace_site_silver_{username}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cb7d875-67f5-41e1-8502-fab2d716022f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This block calculates the degree (number of connected links) for each road node,\n",
    "# assigns a geohash for spatial partitioning, and writes the result as a silver table in Unity Catalog.\n",
    "\n",
    "road_nodes_silver = (\n",
    "    spark.sql(f\"\"\"\n",
    "        WITH tmp AS (\n",
    "            SELECT *, ST_AsEWKB(geometry) AS wkb_geometry\n",
    "            FROM geospatial.networks_geobrix.road_node_{username}\n",
    "            \n",
    "        )\n",
    "        SELECT \n",
    "            a.fid, \n",
    "            a.id, \n",
    "            a.form_of_road_node, \n",
    "            COUNT(DISTINCT b.id) AS degree, \n",
    "            ST_SetSrid(ST_GeomFromEWKB(a.wkb_geometry),27700) AS geometry,\n",
    "            ST_Geohash(ST_Transform(ST_SetSrid(ST_GeomFromEWKB(a.wkb_geometry),27700), 4326), 5) AS geohash\n",
    "        FROM geospatial.networks_geobrix.road_node_{username} a\n",
    "        JOIN geospatial.networks_geobrix.road_link_{username} b\n",
    "            ON a.id = b.start_node\n",
    "            OR a.id = b.end_node\n",
    "        GROUP BY a.fid, a.id, a.form_of_road_node, a.wkb_geometry\n",
    "        ORDER BY COUNT(DISTINCT b.id) DESC\n",
    "    \"\"\")\n",
    "    .repartitionByRange(10, \"geohash\")\n",
    ")\n",
    "\n",
    "road_nodes_silver.write.mode(\"overwrite\").saveAsTable(f\"geospatial.networks_geobrix.road_node_silver_{username}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17a90704-6677-41c5-a2f3-1452d737b94a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This block filters greenspace access points to include only those linked to silver greenspace sites (the attractive green spaces) and with pedestrian or mixed access types.\n",
    "greenspace_entries = (\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT \n",
    "            a.fid, \n",
    "            a.id, \n",
    "            a.access_type, \n",
    "            a.ref_to_greenspace_site, \n",
    "            a.geometry, \n",
    "            ST_Geohash(ST_Transform(a.geometry, 4326), 5) AS geohash\n",
    "        FROM geospatial.greenspaces_geobrix.access_point_{username} a\n",
    "        WHERE a.ref_to_greenspace_site IN (SELECT id FROM greenspace_site_silver_vw)\n",
    "          AND a.access_type IN ('Pedestrian', 'Motor Vehicle And Pedestrian')\n",
    "    \"\"\")\n",
    "    .repartitionByRange(10, \"geohash\")\n",
    ")\n",
    "\n",
    "greenspace_entries.createOrReplaceTempView(\"greenspace_entries_vw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41871907-ab03-4c82-90d2-004502893270",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This block finds the nearest road node for each greenspace entry point using a spatial kNN join (k=1),\n",
    "# calculates the distance to the nearest road node, and writes the result as a silver table in Unity Catalog.\n",
    "entry_road_1nn = (\n",
    "    spark.sql(f\"\"\"\n",
    "        WITH candidate_pairs AS (\n",
    "            SELECT\n",
    "                a.fid,\n",
    "                a.id,\n",
    "                a.access_type,\n",
    "                a.ref_to_greenspace_site,\n",
    "                a.geometry AS a_geometry,\n",
    "                a.geohash,\n",
    "                b.fid AS road_fid,\n",
    "                b.geometry AS b_geometry,\n",
    "                ST_Distance(a.geometry, b.geometry) AS dist\n",
    "            FROM greenspace_entries_vw a\n",
    "            JOIN geospatial.networks_geobrix.road_node_silver_{username} b\n",
    "            ON substr(a.geohash, 1, 6) = substr(b.geohash, 1, 6)  -- spatial pruning!\n",
    "        ),\n",
    "        ranked AS (\n",
    "            SELECT\n",
    "                *,\n",
    "                ROW_NUMBER() OVER (\n",
    "                    PARTITION BY fid\n",
    "                    ORDER BY dist ASC\n",
    "                ) AS rn\n",
    "            FROM candidate_pairs\n",
    "        )\n",
    "        SELECT\n",
    "            fid,\n",
    "            id,\n",
    "            access_type,\n",
    "            ref_to_greenspace_site,\n",
    "            road_fid AS nearest_road_node_fid,\n",
    "            dist AS distance_to_road_node,\n",
    "            a_geometry AS geometry,\n",
    "            geohash\n",
    "        FROM ranked\n",
    "        WHERE rn = 1\n",
    "    \"\"\")\n",
    "    .repartitionByRange(10, \"geohash\")\n",
    ")\n",
    "\n",
    "entry_road_1nn.write.mode(\"overwrite\").saveAsTable(\n",
    "    f\"geospatial.greenspaces_geobrix.access_point_silver_{username}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5394962938826556,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "03-prepare-silver-sedona",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
