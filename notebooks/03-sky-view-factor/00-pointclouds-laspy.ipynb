{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da03e87f-3afe-4e6a-9104-22f8acc23173",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import boto3\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pdal\n",
    "import json\n",
    "import io\n",
    "from laspy import read\n",
    "import pyarrow as pa\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, LongType, BooleanType, MapType\n",
    "from pyspark.sql.functions import lit, col\n",
    "from sedona.spark import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "080775fa-33a5-4b5f-8b7d-9ff2c38a6649",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID'] = dbutils.secrets.get(scope=\"aws_geospatial_s3\", key=\"access_key\")\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = dbutils.secrets.get(scope=\"aws_geospatial_s3\", key=\"secret_key\")\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'eu-west-2'      # Match your bucket region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "660e4f25-0279-482c-9a98-ce2a56814fb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bucket_name = \"revodata-databricks-geospatial\"\n",
    "las_key = \"geospatial-dataset/point-cloud/washington/las-laz/1816.las\"\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Stream file to memory\n",
    "response = s3.get_object(Bucket=bucket_name, Key=las_key)\n",
    "las_data = io.BytesIO(response['Body'].read())\n",
    "\n",
    "# Read from buffer\n",
    "las = read(las_data)\n",
    "print(f\"Loaded {len(las.x)} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0000f9e2-096c-440a-92ca-4e66756937de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(las.x, las.y, c=las.z, s=0.1, alpha=0.5)\n",
    "plt.colorbar(label=\"Elevation (Z)\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Point Cloud Preview\")\n",
    "display(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88eafd2f-a9d9-4a46-a527-92b94dba6857",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config = SedonaContext.builder() .\\\n",
    "    config('spark.jars.packages',\n",
    "           'org.apache.sedona:sedona-spark-shaded-3.3_2.12:1.7.1,'\n",
    "           'org.datasyslab:geotools-wrapper:1.7.1-28.5'). \\\n",
    "    getOrCreate()\n",
    "\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85a0541b-1007-4d8c-b58e-67f645cbd5d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS geospatial.pointcloud;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2a627ba-d14f-4d1f-8ae9-1e9a66fe0e00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset_bucket_name = \"revodata-databricks-geospatial\"\n",
    "dataset_input_dir=\"geospatial-dataset/point-cloud/washington/grid\"\n",
    "gpkg_file = \"pc_grid.gpkg\"\n",
    "df_pc_grid = sedona.read.format(\"geopackage\").option(\"tableName\", \"grid\").load(f\"s3://{dataset_bucket_name}/{dataset_input_dir}/{gpkg_file}\").withColumnRenamed(\"geom\", \"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7eb358e-de3a-4d0b-948b-6b836e4105bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pc_grid.createOrReplaceTempView(\"pc_grid_vw\")\n",
    "\n",
    "df = spark.sql(f\"\"\"\n",
    "SELECT g.fid, \n",
    "ST_X(g.geometry) AS x,\n",
    "ST_Y(g.geometry) AS y,\n",
    "g.geometry AS geometry\n",
    "FROM pc_grid_vw g\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76202eb6-889b-429f-8fcd-575fd96eba27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.limit(1)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "377a72a6-22bf-4972-aeef-a8467b6bdd37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "radius = 100\n",
    "tile_grid = [\"geospatial-dataset/point-cloud/washington/1816.las\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cbadff9-b22e-4269-a7b1-5862452fa345",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# function to get all points lying within range of the defined radius from the viewpoint\n",
    "def getPoints(tile_grid, radius, view_height):\n",
    "    # Viewpoint\n",
    "    center = np.array([x, y])\n",
    "\n",
    "    # Gather points\n",
    "    arraysX, arraysY, arraysZ = [], [], [] # list of arrays of X,Y,Z coords\n",
    "    arrayDistances = [] # Horizontal distances\n",
    "    arrayClasses = [] # Classifications\n",
    "    toBeAdded = []\n",
    "    for tile in tile_grid:\n",
    "        response = s3.get_object(Bucket=bucket_name, Key=tile)\n",
    "        las_data = io.BytesIO(response['Body'].read())\n",
    "        # read the .las file\n",
    "        inFile = read(las_data)\n",
    "        coords = np.vstack((inFile.x, inFile.y)).transpose()\n",
    "        elevation = inFile.z\n",
    "        distances = np.sqrt(np.sum((coords - center)**2, axis=1))\n",
    "        keep_points = np.logical_and(np.logical_and(np.logical_or.reduce((\n",
    "        inFile.classification == 5,\n",
    "        inFile.classification == 6\n",
    "        )),\n",
    "        distances < radius),\n",
    "        elevation >= view_height/1000)\n",
    "        # Get coordinates\n",
    "        arraysX.append(inFile.x[keep_points])\n",
    "        arraysY.append(inFile.y[keep_points])\n",
    "        arraysZ.append(inFile.z[keep_points])\n",
    "        # Get distances\n",
    "        arrayDistances.append(distances[keep_points])\n",
    "        # Get classifications\n",
    "        arrayClasses.append(inFile.classification[keep_points])\n",
    "\n",
    "    # Concatenate all information\n",
    "    X, Y, Z = arraysX[0], arraysY[0], arraysZ[0]\n",
    "    distances = arrayDistances[0]\n",
    "    classes = arrayClasses[0]\n",
    "    for arrayX, arrayY in zip(arraysX[1:], arraysY[1:]):\n",
    "        X = np.hstack([X, arrayX])\n",
    "        Y = np.hstack([Y, arrayY])\n",
    "    for arrayZ in arraysZ[1:]:\n",
    "        Z = np.hstack([Z, arrayZ])\n",
    "    for arDist in arrayDistances[1:]:\n",
    "        distances = np.hstack([distances, arDist])\n",
    "    for arClass in arrayClasses[1:]:\n",
    "        classes = np.hstack([classes, arClass])\n",
    "    return X, Y, Z, distances, classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73698c0e-248c-40a7-a6da-053222337a08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def getheight(tile_grid, x, y):\n",
    "    center = np.array([x, y])\n",
    "    pointheight = 0\n",
    "    points_number = 0\n",
    "\n",
    "    bucket_name = \"revodata-databricks-geospatial\"\n",
    "\n",
    "    # Stream file to memory\n",
    "    for tile in tile_grid:\n",
    "        # read the .las file\n",
    "        response = s3.get_object(Bucket=bucket_name, Key=tile)\n",
    "        las_data = io.BytesIO(response['Body'].read())\n",
    "        file_input = read(las_data)\n",
    "        # keep groundpoints satisfying ground_rules:\n",
    "        # classification 2 for ground, inside las file\n",
    "        # keep points within radius of 5 metres\n",
    "        ground_rules = np.logical_and(\n",
    "        file_input.classification == 2,np.sqrt(np.sum((np.vstack((file_input.x,\n",
    "        file_input.y)).transpose() - center) ** 2, axis=1)) <= 1)\n",
    "        build_rules = np.logical_and(\n",
    "        file_input.classification == 6,\n",
    "        np.sqrt(np.sum((np.vstack((file_input.x,\n",
    "        file_input.y)).transpose() - center) ** 2, axis=1)) <= 1)\n",
    "\n",
    "        ground_points = file_input.points[ground_rules]\n",
    "        build_points = file_input.points[build_rules]\n",
    "        print(build_points)\n",
    "        # make array with heights of each point\n",
    "        if len(ground_points) > len(build_points):\n",
    "            ground_point_heights = np.array((ground_points.z)).transpose()\n",
    "        else:\n",
    "            ground_point_heights = np.array((build_points.z)).transpose()\n",
    "\n",
    "        if len(ground_point_heights) > 0:\n",
    "            pointheight += float(np.sum(ground_point_heights))\n",
    "            points_number += len(ground_point_heights)\n",
    "\n",
    "    # get mean value of points' heights\n",
    "    if points_number > 0:\n",
    "        height = pointheight / points_number\n",
    "        return height\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a447d65c-ba8c-4376-b84d-79c35e260a48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_SVF(radius, dome):\n",
    "    obstructedArea = 0\n",
    "    treeObstruction = 0\n",
    "    buildObstruction = 0\n",
    "    for i in range(0, 180):\n",
    "        for j in range(0, 90):\n",
    "            if dome[i, j] != 0:\n",
    "                v = 90 - (j + 1)\n",
    "                R = math.cos(v * math.pi / 180) * radius\n",
    "                r = math.cos((v + 1) * math.pi / 180) * radius\n",
    "                # calculate area of each obstructed sector (circular sector area calculation)\n",
    "                cell_area = (math.pi / 180.0) * (R ** 2 - r ** 2)\n",
    "                obstructedArea += cell_area\n",
    "                if dome[i, j] in [5]:\n",
    "                    treeObstruction += cell_area\n",
    "                elif dome[i, j] == 6:\n",
    "                    buildObstruction += cell_area\n",
    "    circleArea = math.pi * (radius ** 2)\n",
    "    # SVF: proportion of open area to total area\n",
    "    SVF = (circleArea - obstructedArea) / circleArea\n",
    "    treeObstructionPercentage = treeObstruction / circleArea\n",
    "    buildObstructionPercentage = buildObstruction / circleArea\n",
    "    return SVF, treeObstructionPercentage, buildObstructionPercentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5258407-b67f-48d7-9824-9ffd7c186712",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def createDome(X, Y, Z, dists, classes, view_height):\n",
    "    # Initialize dome\n",
    "    # Indices = (Azimuth, Elevation)\n",
    "    dome = np.zeros((180, 90), dtype=int)\n",
    "    domeDists = np.zeros((180, 90), dtype=int)\n",
    "    if len(X) > 0:\n",
    "        # Azimuths\n",
    "        dX, dY = X - x, Y - y\n",
    "        azimuths = np.arctan2(dY, dX) * 180 / math.pi - 90\n",
    "        azimuths[azimuths < 0] += 360\n",
    "        # Elevations\n",
    "        dZ = Z - view_height / 1000\n",
    "\n",
    "        elevations = np.arctan2(dZ, dists) * 180 / math.pi\n",
    "        # Shade sectors\n",
    "        # Array with dome indices, distances & classifications\n",
    "        data = np.stack((azimuths // 2, elevations // 1, dists, classes),\n",
    "        axis=-1)\n",
    "        # Sort according to indices & classifications\n",
    "        sortData = data[np.lexsort([data[:, 2], data[:, 1], data[:, 0]])]\n",
    "        # Spot where azimuth & elevation values change\n",
    "        azimuth_change = sortData[:, 0][:-1] != sortData[:, 0][1:]\n",
    "        elevation_change = sortData[:, 1][:-1] != sortData[:, 1][1:]\n",
    "        keep = np.where(np.logical_or(azimuth_change, elevation_change))\n",
    "        # Take position of next element, plus add first row\n",
    "        shortestDistance = sortData[\n",
    "        np.insert(keep[0] + 1, 0, 0)] # (inserts second element of change, first position, index of first point)\n",
    "        # Define indices & classifications\n",
    "        hor = shortestDistance[:, 0].astype(int)\n",
    "        ver = shortestDistance[:, 1].astype(int)\n",
    "        classif = shortestDistance[:, 3].astype(int)\n",
    "        dists = shortestDistance[:, 2]\n",
    "        # Update dome\n",
    "        dome[hor, ver] = classif\n",
    "        domeDists[hor, ver] = dists\n",
    "        # Buildings as solids\n",
    "        # Find building positions in dome\n",
    "        # print dome[dome == 6].size\n",
    "        if dome[dome == 6].size > 0:\n",
    "            bhor, bver = np.where(dome == 6)\n",
    "            # Create an array out of them\n",
    "            builds = np.stack((bhor, bver), axis=-1)\n",
    "            shape = (builds.shape[0] + 1, builds.shape[1])\n",
    "            builds = np.append(builds, (bhor[0], bver[0])).reshape(shape)\n",
    "            # Spot azimuth changes\n",
    "            azimuth_change = builds[:, 0][:-1] != builds[:, 0][1:]\n",
    "            keep = np.where(azimuth_change)\n",
    "            # keep = np.insert(np.where(azimuth_change==True), 0, 0)\n",
    "            # Change to building up to roof for each row\n",
    "            roof_rows, roof_cols = builds[keep][:, 0], builds[keep][:, 1]\n",
    "            for roof_row, roof_col in zip(roof_rows, roof_cols):\n",
    "                condition = np.where(np.logical_or(domeDists[roof_row,:roof_col] > domeDists[roof_row, roof_col], dome[roof_row, :roof_col] == 0))\n",
    "                dome[roof_row, :roof_col][condition] = 6\n",
    "    plot(dome)\n",
    "    return dome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87441b74-6bcd-4724-b8ed-4a5056228bdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plot dome\n",
    "def plot(dome):\n",
    "    # Create circular grid\n",
    "    theta = np.linspace(0, 2*np.pi, 180, endpoint=False)\n",
    "    radius = np.linspace(0, 90, 90)\n",
    "    theta_grid, radius_grid = np.meshgrid(theta, radius)\n",
    "    Z = dome.copy().astype(float)\n",
    "    Z = Z.T[::-1, 0:]  # Transpose to (90, 180)\n",
    "    # assign colors depending on class\n",
    "    Z[Z == 0] = 0\n",
    "    Z[np.isin(Z, [5])] = 0.5  # Classes 2-5\n",
    "    Z[Z == 6] = 1\n",
    "    if Z[Z == 6].size == 0:\n",
    "        Z[0,0] = 1\n",
    "        # Verify dimensions\n",
    "    print(f\"theta_grid: {theta.shape}, radius_grid: {radius.shape}, Z: {Z.shape}\")\n",
    "    axes = plt.subplot(111, projection='polar')\n",
    "    cmap = plt.get_cmap('tab20c')\n",
    "    axes.pcolormesh(theta, radius, Z, cmap=cmap)\n",
    "    axes.set_ylim([0, 90])\n",
    "    axes.tick_params(labelleft=False)\n",
    "    axes.set_theta_zero_location(\"N\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "428eb532-7fce-4beb-9492-6e5ac669d173",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tile_grid = [\"geospatial-dataset/point-cloud/washington/las-laz/1816.las\"]\n",
    "\n",
    "x = 395176.7\n",
    "y = 136693.5\n",
    "radius = 100\n",
    "view_height = getheight(tile_grid, x, y)\n",
    "X, Y, Z, distances, classes = getPoints(tile_grid, radius, view_height)\n",
    "print(view_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e80a5fef-872f-4cbb-8505-9380b08ab8c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X, Y, Z, distances, classes = getPoints(tile_grid, radius, view_height)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3d9e18d-4df1-4a6f-9a70-a9d847f4ebbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dome = createDome(X, Y, Z, distances, classes, view_height)\n",
    "plot(dome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d21f010e-be70-4ecf-a56b-76801d1ac918",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SVF, tree_percentage, build_percentage = calculate_SVF(radius, dome)\n",
    "SVF, tree_percentage, build_percentage = round(SVF*100), round(tree_percentage*100), round(build_percentage*100)\n",
    "print ('Sky: {}%'.format(int(SVF)) + \"\\n\" +\n",
    "'Vegetation {}%'.format(int(tree_percentage)) + \"\\n\" +\n",
    "'Building {}%'.format(int(build_percentage)))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8525644592091015,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "00-pointclouds-laspy",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
